{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O--7pLSzEbvG"
   },
   "source": [
    "# Fine-tuning a ceshine/t5-paraphrase-paws-msrp-opinosis model on a detoxification task without prefix\n",
    "Test is performed in collab because I do not have GPU"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive # Using drive to quckly use my dataset\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yz-e60v1jpd3",
    "outputId": "e1f3d728-d299-42eb-9a62-4ac5845296c4"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOsHUjgdIrIW",
    "outputId": "7feece87-83be-4938-86c5-059e784ae62c",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:37.592210Z",
     "end_time": "2023-11-03T21:46:47.760124Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.6)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.10/dist-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# installing huggingface libraries for dataset, models and metrics\n",
    "!pip install datasets transformers[sentencepiece] sacrebleu\n",
    "!pip install numpy==1.24.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:01.766013Z",
     "iopub.status.busy": "2023-09-24T15:10:01.765366Z",
     "iopub.status.idle": "2023-09-24T15:10:01.772400Z",
     "shell.execute_reply": "2023-09-24T15:10:01.771384Z",
     "shell.execute_reply.started": "2023-09-24T15:10:01.765977Z"
    },
    "trusted": true,
    "id": "dyNd_9UDEbvH",
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:47.759125Z",
     "end_time": "2023-11-03T21:46:53.941043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Necessary inputs\n",
    "import warnings\n",
    "\n",
    "from datasets import load_from_disk, load_metric\n",
    "import transformers\n",
    "# import datasets\n",
    "# import random\n",
    "# import pandas as pd\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oqrWaH_EbvI"
   },
   "source": [
    "## Selecting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:01.774778Z",
     "iopub.status.busy": "2023-09-24T15:10:01.773897Z",
     "iopub.status.idle": "2023-09-24T15:10:01.784448Z",
     "shell.execute_reply": "2023-09-24T15:10:01.783216Z",
     "shell.execute_reply.started": "2023-09-24T15:10:01.774744Z"
    },
    "trusted": true,
    "id": "K425zGK_EbvI",
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:53.941043Z",
     "end_time": "2023-11-03T21:46:53.946794Z"
    }
   },
   "outputs": [],
   "source": [
    "# selecting model checkpoint\n",
    "model_checkpoint = \"ceshine/t5-paraphrase-paws-msrp-opinosis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:01.787917Z",
     "iopub.status.busy": "2023-09-24T15:10:01.787594Z",
     "iopub.status.idle": "2023-09-24T15:10:03.219266Z",
     "shell.execute_reply": "2023-09-24T15:10:03.218277Z",
     "shell.execute_reply.started": "2023-09-24T15:10:01.787893Z"
    },
    "id": "IreSlFmlIrIm",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:53.947791Z",
     "end_time": "2023-11-03T21:46:59.005287Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting random seed for transformers library\n",
    "transformers.set_seed(42)\n",
    "\n",
    "# Load my dataset from interim/ ditrectory\n",
    "raw_datasets = load_from_disk(\"/content/drive/MyDrive/interim/\")\n",
    "\n",
    "# Load the BLUE metric\n",
    "metric = load_metric(\"sacrebleu\", split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzC6oGOTEbvJ"
   },
   "source": [
    "## Dataset\n",
    "This dataset is exact one from interim/ directory that was formed using my make_dataset.py script. It contains keys `[\"train\", \"validation\", \"test\"]` - which represents a dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:03.220970Z",
     "iopub.status.busy": "2023-09-24T15:10:03.220604Z",
     "iopub.status.idle": "2023-09-24T15:10:03.229080Z",
     "shell.execute_reply": "2023-09-24T15:10:03.228070Z",
     "shell.execute_reply.started": "2023-09-24T15:10:03.220925Z"
    },
    "id": "GWiVUF0jIrIv",
    "outputId": "a9924780-4935-4435-abbf-04343f21606e",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:59.005287Z",
     "end_time": "2023-11-03T21:46:59.006285Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['toxic_comment', 'neutral_comment'],\n",
       "        num_rows: 404443\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['toxic_comment', 'neutral_comment'],\n",
       "        num_rows: 57778\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['toxic_comment', 'neutral_comment'],\n",
       "        num_rows: 115556\n",
       "    })\n",
       "})"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:35:02.763581Z",
     "iopub.status.busy": "2023-09-24T15:35:02.762411Z",
     "iopub.status.idle": "2023-09-24T15:35:02.772979Z",
     "shell.execute_reply": "2023-09-24T15:35:02.771223Z",
     "shell.execute_reply.started": "2023-09-24T15:35:02.763514Z"
    },
    "id": "X6HrpprwIrIz",
    "outputId": "29575fe4-69a0-4c42-bb89-70a5cddbd310",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:59.005287Z",
     "end_time": "2023-11-03T21:46:59.006285Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'toxic_comment': ['if alkar is flooding her with psychic waste, that explains the high level of neurotransmitters.',\n",
       "  \"now you're getting nasty.\",\n",
       "  'well, we could spare your life, for one.',\n",
       "  \"ah! monkey, you've got to snap out of it.\",\n",
       "  \"i've got orders to put her down.\"],\n",
       " 'neutral_comment': ['if alkar floods her with her mental waste, it would explain the high levels of neurotransmitter.',\n",
       "  \"you're becoming disgusting.\",\n",
       "  'well, we can spare your life.',\n",
       "  'monkey, you have to wake up.',\n",
       "  'i have orders to kill her.']}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# samples from train dataset\n",
    "raw_datasets[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data\n",
    "As usual we will need to preprocess data and tokenize it before passing to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:03.310034Z",
     "iopub.status.busy": "2023-09-24T15:10:03.309664Z",
     "iopub.status.idle": "2023-09-24T15:10:03.505289Z",
     "shell.execute_reply": "2023-09-24T15:10:03.504208Z",
     "shell.execute_reply.started": "2023-09-24T15:10:03.310001Z"
    },
    "id": "eXNLu_-nIrJI",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1809add0-c929-47e2-c920-779ded7e59f4",
    "ExecuteTime": {
     "start_time": "2023-11-03T21:46:59.006285Z",
     "end_time": "2023-11-03T21:47:00.373169Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# we will use autotokenizer for this purpose\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:03.533132Z",
     "iopub.status.busy": "2023-09-24T15:10:03.532860Z",
     "iopub.status.idle": "2023-09-24T15:10:03.539292Z",
     "shell.execute_reply": "2023-09-24T15:10:03.538145Z",
     "shell.execute_reply.started": "2023-09-24T15:10:03.533109Z"
    },
    "trusted": true,
    "id": "LdQIVh2dEbvN",
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:00.397391Z",
     "end_time": "2023-11-03T21:47:00.406020Z"
    }
   },
   "outputs": [],
   "source": [
    "# prefix for model input\n",
    "prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:03.541473Z",
     "iopub.status.busy": "2023-09-24T15:10:03.540621Z",
     "iopub.status.idle": "2023-09-24T15:10:03.549770Z",
     "shell.execute_reply": "2023-09-24T15:10:03.548874Z",
     "shell.execute_reply.started": "2023-09-24T15:10:03.541440Z"
    },
    "id": "vc0BSBLIIrJQ",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:00.405012Z",
     "end_time": "2023-11-03T21:47:00.452844Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "toxic_sent = \"toxic_comment\"\n",
    "target_sent = \"neutral_comment\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex for ex in examples[toxic_sent]]\n",
    "    targets = [ex for ex in examples[target_sent]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:03.551620Z",
     "iopub.status.busy": "2023-09-24T15:10:03.551106Z",
     "iopub.status.idle": "2023-09-24T15:10:03.571019Z",
     "shell.execute_reply": "2023-09-24T15:10:03.569879Z",
     "shell.execute_reply.started": "2023-09-24T15:10:03.551587Z"
    },
    "id": "-b70jh26IrJS",
    "outputId": "9a3671b7-5b53-4cdf-9a96-40cb9523f61f",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:00.418663Z",
     "end_time": "2023-11-03T21:47:00.470796Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [[3, 99, 491, 4031, 19, 18368, 160, 28, 26829, 2670, 6, 24, 3, 9453, 8, 306, 593, 13, 6567, 7031, 1538, 4849, 5, 1], [230, 25, 31, 60, 652, 23147, 5, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[3, 99, 491, 4031, 8347, 7, 160, 28, 160, 2550, 2670, 6, 34, 133, 3209, 8, 306, 1425, 13, 6567, 7031, 1538, 449, 5, 1], [25, 31, 60, 2852, 27635, 53, 5, 1]]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# example of preprocessing\n",
    "preprocess_function(raw_datasets['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T16:09:35.662567Z",
     "iopub.status.busy": "2023-09-24T16:09:35.662099Z",
     "iopub.status.idle": "2023-09-24T16:09:37.545512Z",
     "shell.execute_reply": "2023-09-24T16:09:37.544516Z",
     "shell.execute_reply.started": "2023-09-24T16:09:35.662533Z"
    },
    "id": "DDtsaJeVIrJT",
    "outputId": "d73efa18-ad77-40a3-ff12-3798fdd037d5",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:00.432898Z",
     "end_time": "2023-11-03T21:47:00.542652Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'toxic_comment': 'if alkar is flooding her with psychic waste, that explains the high level of neurotransmitters.',\n",
       " 'neutral_comment': 'if alkar floods her with her mental waste, it would explain the high levels of neurotransmitter.',\n",
       " 'input_ids': [3,\n",
       "  99,\n",
       "  491,\n",
       "  4031,\n",
       "  19,\n",
       "  18368,\n",
       "  160,\n",
       "  28,\n",
       "  26829,\n",
       "  2670,\n",
       "  6,\n",
       "  24,\n",
       "  3,\n",
       "  9453,\n",
       "  8,\n",
       "  306,\n",
       "  593,\n",
       "  13,\n",
       "  6567,\n",
       "  7031,\n",
       "  1538,\n",
       "  4849,\n",
       "  5,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [3,\n",
       "  99,\n",
       "  491,\n",
       "  4031,\n",
       "  8347,\n",
       "  7,\n",
       "  160,\n",
       "  28,\n",
       "  160,\n",
       "  2550,\n",
       "  2670,\n",
       "  6,\n",
       "  34,\n",
       "  133,\n",
       "  3209,\n",
       "  8,\n",
       "  306,\n",
       "  1425,\n",
       "  13,\n",
       "  6567,\n",
       "  7031,\n",
       "  1538,\n",
       "  449,\n",
       "  5,\n",
       "  1]}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# for the example purpose we will crop the dataset and select first 5000 for train\n",
    "# and 500 for validation and test\n",
    "cropped_datasets = raw_datasets\n",
    "cropped_datasets['train'] = raw_datasets['train'].select(range(5000))\n",
    "cropped_datasets['validation'] = raw_datasets['validation'].select(range(500))\n",
    "cropped_datasets['test'] = raw_datasets['test'].select(range(500))\n",
    "tokenized_datasets = cropped_datasets.map(preprocess_function, batched=True)\n",
    "tokenized_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:03.605060Z",
     "iopub.status.busy": "2023-09-24T15:10:03.604730Z",
     "iopub.status.idle": "2023-09-24T15:10:04.671893Z",
     "shell.execute_reply": "2023-09-24T15:10:04.670859Z",
     "shell.execute_reply.started": "2023-09-24T15:10:03.605029Z"
    },
    "id": "TlqNaB8jIrJW",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:00.499847Z",
     "end_time": "2023-11-03T21:47:06.508885Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "# create a model for the pretrained model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install accelerate -U"
   ],
   "metadata": {
    "id": "GDLntu65If9r",
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:06.510878Z",
     "end_time": "2023-11-03T21:47:06.515276Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "af63ac7d-8b16-4304-8fee-0a675c3321ed"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.17.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:04.674163Z",
     "iopub.status.busy": "2023-09-24T15:10:04.673474Z",
     "iopub.status.idle": "2023-09-24T15:10:04.681771Z",
     "shell.execute_reply": "2023-09-24T15:10:04.680562Z",
     "shell.execute_reply.started": "2023-09-24T15:10:04.674126Z"
    },
    "id": "Bliy8zgjIrJY",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:06.516271Z",
     "end_time": "2023-11-03T21:47:06.547212Z"
    }
   },
   "outputs": [],
   "source": [
    "# defining the parameters for training\n",
    "batch_size = 32\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{toxic_sent}-to-{target_sent}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    report_to='tensorboard',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:04.684376Z",
     "iopub.status.busy": "2023-09-24T15:10:04.683883Z",
     "iopub.status.idle": "2023-09-24T15:10:04.693774Z",
     "shell.execute_reply": "2023-09-24T15:10:04.692863Z",
     "shell.execute_reply.started": "2023-09-24T15:10:04.684341Z"
    },
    "trusted": true,
    "id": "ypTy8nYUEbvQ",
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:06.530729Z",
     "end_time": "2023-11-03T21:47:06.557175Z"
    }
   },
   "outputs": [],
   "source": [
    "# instead of writing collate_fn function we will use DataCollatorForSeq2Seq\n",
    "# simliarly it implements the batch creation for training\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:04.695838Z",
     "iopub.status.busy": "2023-09-24T15:10:04.695457Z",
     "iopub.status.idle": "2023-09-24T15:10:04.707222Z",
     "shell.execute_reply": "2023-09-24T15:10:04.706315Z",
     "shell.execute_reply.started": "2023-09-24T15:10:04.695806Z"
    },
    "id": "UmvbnJ9JIrJd",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:06.539578Z",
     "end_time": "2023-11-03T21:47:06.558173Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# simple postprocessing for text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "# compute metrics function to pass to trainer\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:04.709249Z",
     "iopub.status.busy": "2023-09-24T15:10:04.708526Z",
     "iopub.status.idle": "2023-09-24T15:10:04.806768Z",
     "shell.execute_reply": "2023-09-24T15:10:04.805816Z",
     "shell.execute_reply.started": "2023-09-24T15:10:04.709216Z"
    },
    "id": "imY1oC3SIrJf",
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-03T21:47:06.546206Z",
     "end_time": "2023-11-03T21:47:06.636354Z"
    }
   },
   "outputs": [],
   "source": [
    "# instead of writing train loop we will use Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:10:04.808506Z",
     "iopub.status.busy": "2023-09-24T15:10:04.808050Z",
     "iopub.status.idle": "2023-09-24T15:18:44.110261Z",
     "shell.execute_reply": "2023-09-24T15:18:44.109150Z",
     "shell.execute_reply.started": "2023-09-24T15:10:04.808459Z"
    },
    "id": "uNx5pyRlIrJh",
    "outputId": "61fcadd1-f8a7-4297-b673-e7eaa3734976",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1570' max='1570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1570/1570 11:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.557626</td>\n",
       "      <td>21.686000</td>\n",
       "      <td>13.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.487002</td>\n",
       "      <td>23.025000</td>\n",
       "      <td>14.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.456288</td>\n",
       "      <td>24.129800</td>\n",
       "      <td>14.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.707800</td>\n",
       "      <td>1.440308</td>\n",
       "      <td>24.290800</td>\n",
       "      <td>14.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.707800</td>\n",
       "      <td>1.427558</td>\n",
       "      <td>24.268900</td>\n",
       "      <td>14.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.707800</td>\n",
       "      <td>1.422584</td>\n",
       "      <td>24.621200</td>\n",
       "      <td>13.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.488700</td>\n",
       "      <td>1.416779</td>\n",
       "      <td>24.795100</td>\n",
       "      <td>13.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.488700</td>\n",
       "      <td>1.414756</td>\n",
       "      <td>24.863000</td>\n",
       "      <td>13.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.488700</td>\n",
       "      <td>1.413583</td>\n",
       "      <td>24.864800</td>\n",
       "      <td>14.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.427400</td>\n",
       "      <td>1.413186</td>\n",
       "      <td>24.819000</td>\n",
       "      <td>13.998000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1570, training_loss=1.53495962543852, metrics={'train_runtime': 696.1116, 'train_samples_per_second': 71.828, 'train_steps_per_second': 2.255, 'total_flos': 2830655119564800.0, 'train_loss': 1.53495962543852, 'epoch': 10.0})"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:19:29.403450Z",
     "iopub.status.busy": "2023-09-24T15:19:29.403061Z",
     "iopub.status.idle": "2023-09-24T15:19:30.003295Z",
     "shell.execute_reply": "2023-09-24T15:19:30.002182Z",
     "shell.execute_reply.started": "2023-09-24T15:19:29.403420Z"
    },
    "trusted": true,
    "id": "FWI1Xp8WEbvS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# saving model\n",
    "trainer.save_model('best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:19:30.753608Z",
     "iopub.status.busy": "2023-09-24T15:19:30.753167Z",
     "iopub.status.idle": "2023-09-24T15:19:31.676057Z",
     "shell.execute_reply": "2023-09-24T15:19:31.675005Z",
     "shell.execute_reply.started": "2023-09-24T15:19:30.753575Z"
    },
    "trusted": true,
    "id": "F4pKDYxrEbvS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# loading the model and run inference for it\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('best')\n",
    "model.eval()\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T15:19:31.744595Z",
     "iopub.status.busy": "2023-09-24T15:19:31.744257Z",
     "iopub.status.idle": "2023-09-24T15:19:31.749935Z",
     "shell.execute_reply": "2023-09-24T15:19:31.748926Z",
     "shell.execute_reply.started": "2023-09-24T15:19:31.744568Z"
    },
    "trusted": true,
    "id": "GHzipG6MEbvS",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def translate(model, inference_request, tokenizer=tokenizer):\n",
    "    input_ids = tokenizer(inference_request, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids=input_ids)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True,temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T16:17:24.580846Z",
     "iopub.status.busy": "2023-09-24T16:17:24.580402Z",
     "iopub.status.idle": "2023-09-24T16:17:24.852369Z",
     "shell.execute_reply": "2023-09-24T16:17:24.851186Z",
     "shell.execute_reply.started": "2023-09-24T16:17:24.580812Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWDl7KUTEbvT",
    "outputId": "70ee33ca-1975-4c2d-f22d-2e332b88a830",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "now you're a cocky, bastard.\n"
     ]
    }
   ],
   "source": [
    "inference_request = prefix + \"Now you're getting cocky, bastard\"\n",
    "translate(model, inference_request,tokenizer)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
